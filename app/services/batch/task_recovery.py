"""
ä»»åŠ¡æ¢å¤æœåŠ¡ - å¤„ç†æœåŠ¡å™¨é‡å¯åçš„ä»»åŠ¡æ¢å¤
"""
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime

from sqlalchemy import select, update
from sqlalchemy.orm import selectinload

from app.core.logging import get_logger
from app.core.database import get_db_session
from app.models.batch_task import BatchTask, TaskExecution, TaskStatus, ExecutionStatus
from app.models.workflow import Workflow

logger = get_logger(__name__)


class TaskRecoveryService:
    """ä»»åŠ¡æ¢å¤æœåŠ¡"""
    
    def __init__(self):
        self.recovered_tasks: List[str] = []
        self.failed_recoveries: List[str] = []
    
    async def recover_interrupted_tasks(self) -> Dict[str, Any]:
        """
        æ¢å¤è¢«ä¸­æ–­çš„ä»»åŠ¡
        
        Returns:
            æ¢å¤ç»“æœç»Ÿè®¡
        """
        logger.info("ğŸ”„ å¼€å§‹æ£€æŸ¥å’Œæ¢å¤è¢«ä¸­æ–­çš„æ‰¹é‡ä»»åŠ¡...")
        
        try:
            # æŸ¥æ‰¾éœ€è¦æ¢å¤çš„ä»»åŠ¡
            interrupted_tasks = await self._find_interrupted_tasks()
            
            if not interrupted_tasks:
                logger.info("âœ… æ²¡æœ‰å‘ç°éœ€è¦æ¢å¤çš„ä»»åŠ¡")
                return {
                    "total_found": 0,
                    "recovered": 0,
                    "failed": 0,
                    "recovered_tasks": [],
                    "failed_tasks": []
                }
            
            logger.info(f"ğŸ“‹ å‘ç° {len(interrupted_tasks)} ä¸ªéœ€è¦æ¢å¤çš„ä»»åŠ¡")
            
            # é€ä¸ªæ¢å¤ä»»åŠ¡
            for task in interrupted_tasks:
                try:
                    await self._recover_single_task(task)
                    self.recovered_tasks.append(task.id)
                    logger.info(f"âœ… ä»»åŠ¡æ¢å¤æˆåŠŸ: {task.id} - {task.name}")
                except Exception as e:
                    self.failed_recoveries.append(task.id)
                    logger.error(f"âŒ ä»»åŠ¡æ¢å¤å¤±è´¥: {task.id} - {task.name}, é”™è¯¯: {e}")
            
            # è¿”å›æ¢å¤ç»“æœ
            result = {
                "total_found": len(interrupted_tasks),
                "recovered": len(self.recovered_tasks),
                "failed": len(self.failed_recoveries),
                "recovered_tasks": self.recovered_tasks,
                "failed_tasks": self.failed_recoveries
            }
            
            logger.info(f"ğŸ¯ ä»»åŠ¡æ¢å¤å®Œæˆ: å‘ç° {result['total_found']} ä¸ªï¼ŒæˆåŠŸæ¢å¤ {result['recovered']} ä¸ªï¼Œå¤±è´¥ {result['failed']} ä¸ª")
            
            return result
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ä»»åŠ¡æ¢å¤è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
            raise
    
    async def _find_interrupted_tasks(self) -> List[BatchTask]:
        """
        æŸ¥æ‰¾è¢«ä¸­æ–­çš„ä»»åŠ¡
        
        Returns:
            éœ€è¦æ¢å¤çš„æ‰¹é‡ä»»åŠ¡åˆ—è¡¨
        """
        try:
            async with get_db_session() as db:
                # æŸ¥æ‰¾çŠ¶æ€ä¸º RUNNING çš„æ‰¹é‡ä»»åŠ¡
                result = await db.execute(
                    select(BatchTask)
                    .where(BatchTask.status == TaskStatus.RUNNING)
                    .options(selectinload(BatchTask.executions))
                    .order_by(BatchTask.created_at)
                )
                
                interrupted_tasks = result.scalars().all()
                
                # è¿‡æ»¤å‡ºçœŸæ­£éœ€è¦æ¢å¤çš„ä»»åŠ¡
                tasks_to_recover = []
                for task in interrupted_tasks:
                    if await self._should_recover_task(task):
                        tasks_to_recover.append(task)
                    else:
                        # æ›´æ–°å·²å®Œæˆä½†çŠ¶æ€é”™è¯¯çš„ä»»åŠ¡
                        await self._fix_completed_task_status(task)
                
                return tasks_to_recover
                
        except Exception as e:
            logger.error(f"æŸ¥æ‰¾è¢«ä¸­æ–­ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def _should_recover_task(self, task: BatchTask) -> bool:
        """
        åˆ¤æ–­ä»»åŠ¡æ˜¯å¦éœ€è¦æ¢å¤
        
        Args:
            task: æ‰¹é‡ä»»åŠ¡
            
        Returns:
            æ˜¯å¦éœ€è¦æ¢å¤
        """
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„å­ä»»åŠ¡
            async with get_db_session() as db:
                result = await db.execute(
                    select(TaskExecution)
                    .where(
                        TaskExecution.batch_task_id == task.id,
                        TaskExecution.status == ExecutionStatus.PENDING
                    )
                )
                
                pending_executions = result.scalars().all()
                
                # å¦‚æœæœ‰ PENDING çŠ¶æ€çš„å­ä»»åŠ¡ï¼Œåˆ™éœ€è¦æ¢å¤
                if pending_executions:
                    logger.info(f"ğŸ“ ä»»åŠ¡ {task.id} æœ‰ {len(pending_executions)} ä¸ªå¾…å¤„ç†çš„å­ä»»åŠ¡ï¼Œéœ€è¦æ¢å¤")
                    return True
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ RUNNING çŠ¶æ€çš„å­ä»»åŠ¡ï¼ˆå¯èƒ½å› ä¸ºæœåŠ¡å™¨é‡å¯è€Œä¸­æ–­ï¼‰
                result = await db.execute(
                    select(TaskExecution)
                    .where(
                        TaskExecution.batch_task_id == task.id,
                        TaskExecution.status == ExecutionStatus.RUNNING
                    )
                )
                
                running_executions = result.scalars().all()
                
                if running_executions:
                    logger.info(f"ğŸ”„ ä»»åŠ¡ {task.id} æœ‰ {len(running_executions)} ä¸ªè¿è¡Œä¸­çš„å­ä»»åŠ¡ï¼Œéœ€è¦æ¢å¤")
                    # å°† RUNNING çŠ¶æ€çš„å­ä»»åŠ¡é‡ç½®ä¸º PENDING
                    await db.execute(
                        update(TaskExecution)
                        .where(
                            TaskExecution.batch_task_id == task.id,
                            TaskExecution.status == ExecutionStatus.RUNNING
                        )
                        .values(status=ExecutionStatus.PENDING)
                    )
                    await db.commit()
                    return True
                
                return False
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥ä»»åŠ¡æ¢å¤éœ€æ±‚å¤±è´¥: {task.id}, é”™è¯¯: {e}")
            return False
    
    async def _fix_completed_task_status(self, task: BatchTask):
        """
        ä¿®å¤å·²å®Œæˆä½†çŠ¶æ€é”™è¯¯çš„ä»»åŠ¡
        
        Args:
            task: æ‰¹é‡ä»»åŠ¡
        """
        try:
            async with get_db_session() as db:
                # ç»Ÿè®¡å­ä»»åŠ¡çŠ¶æ€
                result = await db.execute(
                    select(TaskExecution)
                    .where(TaskExecution.batch_task_id == task.id)
                )
                
                executions = result.scalars().all()
                
                if not executions:
                    return
                
                total_count = len(executions)
                completed_count = sum(1 for e in executions if e.status == ExecutionStatus.SUCCESS)
                failed_count = sum(1 for e in executions if e.status == ExecutionStatus.FAILED)
                pending_count = sum(1 for e in executions if e.status == ExecutionStatus.PENDING)
                running_count = sum(1 for e in executions if e.status == ExecutionStatus.RUNNING)
                
                # å¦‚æœæ‰€æœ‰å­ä»»åŠ¡éƒ½å·²å®Œæˆï¼Œæ›´æ–°æ‰¹é‡ä»»åŠ¡çŠ¶æ€
                if pending_count == 0 and running_count == 0:
                    final_status = TaskStatus.COMPLETED if failed_count == 0 else TaskStatus.COMPLETED
                    
                    await db.execute(
                        update(BatchTask)
                        .where(BatchTask.id == task.id)
                        .values(
                            status=final_status,
                            completed_items=completed_count,
                            failed_items=failed_count,
                            progress_percentage=100.0,
                            completed_at=datetime.utcnow()
                        )
                    )
                    await db.commit()
                    
                    logger.info(f"ğŸ”§ ä¿®å¤ä»»åŠ¡çŠ¶æ€: {task.id} -> {final_status}")
                
        except Exception as e:
            logger.error(f"ä¿®å¤ä»»åŠ¡çŠ¶æ€å¤±è´¥: {task.id}, é”™è¯¯: {e}")
    
    async def _recover_single_task(self, task: BatchTask):
        """
        æ¢å¤å•ä¸ªæ‰¹é‡ä»»åŠ¡
        
        Args:
            task: è¦æ¢å¤çš„æ‰¹é‡ä»»åŠ¡
        """
        try:
            logger.info(f"ğŸ”„ å¼€å§‹æ¢å¤ä»»åŠ¡: {task.id} - {task.name}")
            
            # è·å–å·¥ä½œæµé…ç½®
            workflow_config = await self._get_workflow_config(task.workflow_id)
            if not workflow_config:
                raise Exception(f"æ— æ³•è·å–å·¥ä½œæµé…ç½®: {task.workflow_id}")
            
            # å¯¼å…¥æ‰¹é‡å¤„ç†å™¨ï¼ˆé¿å…å¾ªç¯å¯¼å…¥ï¼‰
            from app.services.batch.batch_processor import BatchProcessor
            from app.services.batch.progress_tracker import progress_tracker
            
            # åˆ›å»ºæ‰¹é‡å¤„ç†å™¨å®ä¾‹
            batch_processor = BatchProcessor()
            
            # å¯åŠ¨æ‰¹é‡ä»»åŠ¡æ¢å¤
            success = await batch_processor.start_batch_task(
                task.id,
                workflow_config,
                is_recovery=True  # æ ‡è®°ä¸ºæ¢å¤æ¨¡å¼
            )
            
            if not success:
                raise Exception("æ‰¹é‡å¤„ç†å™¨å¯åŠ¨å¤±è´¥")
            
            # å¼€å§‹è¿›åº¦è¿½è¸ª
            progress_tracker.start_tracking(task.id)
            
            logger.info(f"âœ… ä»»åŠ¡æ¢å¤å¯åŠ¨æˆåŠŸ: {task.id}")
            
        except Exception as e:
            logger.error(f"æ¢å¤å•ä¸ªä»»åŠ¡å¤±è´¥: {task.id}, é”™è¯¯: {e}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            try:
                async with get_db_session() as db:
                    await db.execute(
                        update(BatchTask)
                        .where(BatchTask.id == task.id)
                        .values(
                            status=TaskStatus.FAILED,
                            error_message=f"ä»»åŠ¡æ¢å¤å¤±è´¥: {str(e)}",
                            completed_at=datetime.utcnow()
                        )
                    )
                    await db.commit()
            except Exception as update_error:
                logger.error(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {task.id}, é”™è¯¯: {update_error}")
            
            raise
    
    async def _get_workflow_config(self, workflow_id: str) -> Optional[Dict[str, Any]]:
        """
        è·å–å·¥ä½œæµé…ç½®
        
        Args:
            workflow_id: å·¥ä½œæµID
            
        Returns:
            å·¥ä½œæµé…ç½®å­—å…¸
        """
        try:
            async with get_db_session() as db:
                result = await db.execute(
                    select(Workflow).where(Workflow.id == workflow_id)
                )
                
                workflow = result.scalar_one_or_none()
                
                if not workflow:
                    logger.error(f"å·¥ä½œæµä¸å­˜åœ¨: {workflow_id}")
                    return None
                
                return {
                    "base_url": workflow.base_url,
                    "api_key": workflow.api_key
                }
                
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œæµé…ç½®å¤±è´¥: {workflow_id}, é”™è¯¯: {e}")
            return None
    
    def get_recovery_summary(self) -> Dict[str, Any]:
        """
        è·å–æ¢å¤ç»“æœæ‘˜è¦
        
        Returns:
            æ¢å¤ç»“æœæ‘˜è¦
        """
        return {
            "recovered_count": len(self.recovered_tasks),
            "failed_count": len(self.failed_recoveries),
            "recovered_tasks": self.recovered_tasks.copy(),
            "failed_tasks": self.failed_recoveries.copy()
        }


# åˆ›å»ºå…¨å±€å®ä¾‹
task_recovery_service = TaskRecoveryService() 