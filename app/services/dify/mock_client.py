"""
æ¨¡æ‹ŸDifyå®¢æˆ·ç«¯ - ç”¨äºPhase 4.1æµ‹è¯•
"""

import asyncio
import json
import random
import time
from typing import Dict, Any, Optional
from pathlib import Path

from .models import WorkflowExecutionResponse, WorkflowRunStatus
from ...core.logging import logger


class MockDifyClient:
    """æ¨¡æ‹Ÿçš„Difyå®¢æˆ·ç«¯ï¼Œç”¨äºæµ‹è¯•æ‰¹é‡å¤„ç†åŠŸèƒ½"""
    
    def __init__(self, base_url: str, api_key: str):
        self.base_url = base_url
        self.api_key = api_key
        self.session = None
        
        # åŠ è½½æ¨¡æ‹Ÿå“åº”æ•°æ®
        self._load_mock_responses()
    
    def _load_mock_responses(self):
        """åŠ è½½æ¨¡æ‹Ÿå“åº”æ•°æ®"""
        try:
            mock_file = Path("mock_dify_responses.json")
            if mock_file.exists():
                with open(mock_file, 'r', encoding='utf-8') as f:
                    self.mock_responses = json.load(f)
            else:
                # é»˜è®¤æ¨¡æ‹Ÿå“åº”
                self.mock_responses = [
                    {
                        "id": f"run-{i:03d}",
                        "workflow_id": "test-workflow-001",
                        "status": "succeeded",
                        "outputs": {"text": f"è¿™æ˜¯ç¬¬{i+1}ä¸ªæµ‹è¯•å“åº”"},
                        "error": None,
                        "elapsed_time": random.uniform(1.0, 5.0),
                        "total_tokens": random.randint(100, 300),
                        "created_at": int(time.time()),
                        "finished_at": int(time.time()) + random.randint(1, 5)
                    }
                    for i in range(10)
                ]
        except Exception as e:
            logger.warning(f"åŠ è½½æ¨¡æ‹Ÿå“åº”å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤å“åº”")
            self.mock_responses = []
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        logger.info(f"ğŸ”— æ¨¡æ‹ŸDifyå®¢æˆ·ç«¯è¿æ¥: {self.base_url}")
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        logger.info(f"ğŸ”Œ æ¨¡æ‹ŸDifyå®¢æˆ·ç«¯æ–­å¼€è¿æ¥")
        pass
    
    async def execute_workflow(self, inputs: Dict[str, Any]) -> WorkflowExecutionResponse:
        """
        æ¨¡æ‹Ÿæ‰§è¡Œå·¥ä½œæµ
        
        Args:
            inputs: è¾“å…¥å‚æ•°
            
        Returns:
            WorkflowExecutionResponse: æ‰§è¡Œå“åº”
        """
        logger.info(f"ğŸ­ æ¨¡æ‹Ÿæ‰§è¡Œå·¥ä½œæµ")
        logger.info(f"   è¾“å…¥å‚æ•°: {json.dumps(inputs, ensure_ascii=False)}")
        
        # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        delay = random.uniform(0.5, 3.0)
        logger.info(f"   æ¨¡æ‹Ÿå»¶è¿Ÿ: {delay:.2f}ç§’")
        await asyncio.sleep(delay)
        
        # æ¨¡æ‹Ÿå¶å‘é”™è¯¯ï¼ˆ10%æ¦‚ç‡ï¼‰
        if random.random() < 0.1:
            error_messages = [
                "ç½‘ç»œè¿æ¥è¶…æ—¶",
                "APIè°ƒç”¨é™åˆ¶",
                "å·¥ä½œæµæ‰§è¡Œå¤±è´¥",
                "å‚æ•°éªŒè¯é”™è¯¯"
            ]
            error_msg = random.choice(error_messages)
            logger.error(f"   æ¨¡æ‹Ÿé”™è¯¯: {error_msg}")
            raise Exception(f"æ¨¡æ‹ŸDify APIé”™è¯¯: {error_msg}")
        
        # ç”Ÿæˆæ¨¡æ‹Ÿå“åº”
        response_data = self._generate_mock_response(inputs)
        
        logger.info(f"   æ¨¡æ‹Ÿå“åº”: {json.dumps(response_data, ensure_ascii=False)}")
        
        # åˆ›å»ºå“åº”å¯¹è±¡ - æ¨¡æ‹ŸçœŸå®Dify APIçš„å“åº”æ ¼å¼
        response = WorkflowExecutionResponse(
            workflow_run_id=response_data["id"],
            task_id=response_data["id"],
            data=response_data
        )
        
        return response
    
    def _generate_mock_response(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ‹Ÿå“åº”æ•°æ®"""
        
        # åŸºäºè¾“å…¥ç”Ÿæˆä¸ªæ€§åŒ–å“åº”
        query = inputs.get("query", "é»˜è®¤æŸ¥è¯¢")
        context = inputs.get("context", "")
        
        # ç”Ÿæˆæ¨¡æ‹Ÿè¾“å‡º
        mock_outputs = {
            "text": f"é’ˆå¯¹æŸ¥è¯¢ã€Œ{query}ã€çš„å›ç­”",
            "summary": f"åŸºäºä¸Šä¸‹æ–‡ã€Œ{context}ã€çš„æ€»ç»“" if context else "æ— ä¸Šä¸‹æ–‡æ€»ç»“",
            "confidence": random.uniform(0.7, 0.95)
        }
        
        # éšæœºé€‰æ‹©è¾“å‡ºæ ¼å¼
        output_formats = [
            {"text": mock_outputs["text"]},
            {"result": mock_outputs["text"], "confidence": mock_outputs["confidence"]},
            {"answer": mock_outputs["text"], "summary": mock_outputs["summary"]},
            mock_outputs  # å®Œæ•´è¾“å‡º
        ]
        
        selected_output = random.choice(output_formats)
        
        return {
            "id": f"run-{random.randint(1000, 9999)}",
            "workflow_id": "test-workflow-001",
            "status": "succeeded",
            "outputs": selected_output,
            "error": None,
            "elapsed_time": random.uniform(1.0, 5.0),
            "total_tokens": random.randint(100, 500),
            "total_steps": random.randint(2, 6),
            "created_at": int(time.time()),
            "finished_at": int(time.time()) + random.randint(1, 5)
        }
    
    async def get_workflow_parameters(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿè·å–å·¥ä½œæµå‚æ•°"""
        logger.info(f"ğŸ­ æ¨¡æ‹Ÿè·å–å·¥ä½œæµå‚æ•°")
        
        await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        
        return {
            "parameters": [
                {
                    "name": "query",
                    "type": "string",
                    "required": True,
                    "description": "ç”¨æˆ·æŸ¥è¯¢å†…å®¹"
                },
                {
                    "name": "context",
                    "type": "string", 
                    "required": False,
                    "description": "ä¸Šä¸‹æ–‡ä¿¡æ¯"
                }
            ]
        }
    
    async def get_application_info(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿè·å–åº”ç”¨ä¿¡æ¯"""
        logger.info(f"ğŸ­ æ¨¡æ‹Ÿè·å–åº”ç”¨ä¿¡æ¯")
        
        await asyncio.sleep(0.3)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        
        return {
            "name": "æµ‹è¯•å·¥ä½œæµåº”ç”¨",
            "description": "ç”¨äºPhase 4.1æµ‹è¯•çš„æ¨¡æ‹Ÿåº”ç”¨",
            "tags": ["æµ‹è¯•", "æ¨¡æ‹Ÿ", "æ‰¹é‡å¤„ç†"],
            "created_at": "2024-06-13T00:00:00Z"
        } 