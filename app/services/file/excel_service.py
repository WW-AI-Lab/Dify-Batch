"""
Excelæ–‡ä»¶å¤„ç†æœåŠ¡
"""
import io
import os
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path

import pandas as pd
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.worksheet.worksheet import Worksheet

from app.services.dify.models import WorkflowParameters, WorkflowParameter, WorkflowParameterType
from app.core.exceptions import FileProcessingException
from app.core.logging import get_logger
from .template_generator import TemplateGenerator

logger = get_logger(__name__)


class ExcelService:
    """Excelæ–‡ä»¶å¤„ç†æœåŠ¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–ExcelæœåŠ¡"""
        self.max_file_size = 200 * 1024 * 1024  # 200MBï¼ˆæ”¯æŒå¤§æ–‡ä»¶ï¼‰
        self.supported_extensions = ['.xlsx', '.xls']
        self.template_generator = TemplateGenerator()
        
    def generate_template(self, parameters: WorkflowParameters) -> io.BytesIO:
        """
        ç”ŸæˆExcelæ¨¡æ¿æ–‡ä»¶
        
        Args:
            parameters: å·¥ä½œæµå‚æ•°ä¿¡æ¯
            
        Returns:
            Excelæ–‡ä»¶çš„å­—èŠ‚æµ
        """
        try:
            logger.info(f"å¼€å§‹ç”ŸæˆExcelæ¨¡æ¿: {parameters.workflow_name}")
            return self.template_generator.generate_workflow_template(parameters)
        except Exception as e:
            logger.error(f"ç”ŸæˆExcelæ¨¡æ¿å¤±è´¥: {str(e)}")
            raise FileProcessingException(f"ç”ŸæˆExcelæ¨¡æ¿å¤±è´¥: {str(e)}")
    

    
    def parse_excel_file(self, file_path: str) -> Tuple[List[Dict[str, Any]], List[str]]:
        """
        è§£æExcelæ–‡ä»¶
        
        Args:
            file_path: Excelæ–‡ä»¶è·¯å¾„
            
        Returns:
            (æ•°æ®è¡Œåˆ—è¡¨, å‚æ•°ååˆ—è¡¨)
        """
        try:
            logger.info(f"å¼€å§‹è§£æExcelæ–‡ä»¶: {file_path}")
            
            # éªŒè¯æ–‡ä»¶
            self._validate_file(file_path)
            
            # è¯»å–Excelæ–‡ä»¶ï¼ˆä¼˜åŒ–å¤§æ–‡ä»¶å¤„ç†ï¼‰
            df = pd.read_excel(file_path, sheet_name="æ‰¹é‡æ•°æ®", header=0, engine='openpyxl')
            
            # è·å–å‚æ•°åˆ—åï¼ˆæ’é™¤ç»“æœåˆ—ï¼‰
            columns = df.columns.tolist()
            if "æ‰§è¡Œç»“æœ" in columns:
                columns.remove("æ‰§è¡Œç»“æœ")
            
            # æ¸…ç†åˆ—åï¼Œç§»é™¤å¿…å¡«æ ‡è®° *
            clean_columns = []
            for col in columns:
                clean_col = col.strip()
                if clean_col.endswith(' *'):
                    clean_col = clean_col[:-2].strip()
                clean_columns.append(clean_col)
            columns = clean_columns
            
            # è¿‡æ»¤ç©ºè¡Œå’Œç¤ºä¾‹è¡Œ
            df = df.dropna(how='all')  # åˆ é™¤å®Œå…¨ç©ºç™½çš„è¡Œ
            
            # è·³è¿‡æè¿°è¡Œå’Œç¤ºä¾‹è¡Œï¼ˆç¬¬2ã€3è¡Œï¼‰
            # å¦‚æœç¬¬ä¸€è¡Œæ•°æ®çœ‹èµ·æ¥åƒæè¿°è¡Œï¼Œä¹Ÿè¦è·³è¿‡
            if len(df) > 0:
                # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦ä¸ºæè¿°è¡Œï¼ˆåŒ…å«å‚æ•°åç§°æœ¬èº«æˆ–æè¿°æ€§æ–‡å­—ï¼‰
                first_row = df.iloc[0]
                is_description_row = False
                
                for col_idx, col_name in enumerate(df.columns):
                    if col_idx < len(first_row):
                        cell_value = str(first_row.iloc[col_idx]).strip()
                        clean_col_name = col_name.strip()
                        if clean_col_name.endswith(' *'):
                            clean_col_name = clean_col_name[:-2].strip()
                        
                        # å¦‚æœå•å…ƒæ ¼å€¼å°±æ˜¯åˆ—åæœ¬èº«ï¼Œæˆ–è€…æ˜¯å¸¸è§çš„æè¿°è¯ï¼Œåˆ™è®¤ä¸ºæ˜¯æè¿°è¡Œ
                        if (cell_value == clean_col_name or 
                            cell_value in ['æœç´¢è¯', 'å‚æ•°', 'è¾“å…¥', 'æ•°æ®', 'å†…å®¹', 'å€¼', 'ç¤ºä¾‹']):
                            is_description_row = True
                            break
                
                # è·³è¿‡æè¿°è¡Œ
                if is_description_row:
                    df = df.iloc[1:]
                
                # ğŸ”§ ä¿®å¤ï¼šå¢å¼ºç¤ºä¾‹è¡Œæ£€æµ‹é€»è¾‘
                if len(df) > 0:
                    # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦ä¸ºç¤ºä¾‹è¡Œ
                    first_row = df.iloc[0]
                    is_example_row = False
                    
                    for col_idx, col_name in enumerate(df.columns):
                        if col_idx < len(first_row):
                            cell_value = str(first_row.iloc[col_idx]).strip()
                            clean_col_name = col_name.strip()
                            if clean_col_name.endswith(' *'):
                                clean_col_name = clean_col_name[:-2].strip()
                            
                            # æ£€æµ‹å¸¸è§çš„ç¤ºä¾‹æ•°æ®
                            example_values = [
                                'iPhone', 'iphone', 'IPHONE',  # å¸¸è§ç¤ºä¾‹æ‰‹æœº
                                'ç¤ºä¾‹', 'ä¾‹å­', 'example', 'sample',  # ç¤ºä¾‹æ ‡è¯†è¯
                                'ç¤ºä¾‹å‚æ•°', 'ç¤ºä¾‹æ•°æ®', 'ç¤ºä¾‹å†…å®¹',  # ç¤ºä¾‹å‚æ•°
                                'test', 'Test', 'TEST',  # æµ‹è¯•æ•°æ®
                                'æµ‹è¯•', 'æµ‹è¯•æ•°æ®', 'æµ‹è¯•å†…å®¹'  # ä¸­æ–‡æµ‹è¯•æ•°æ®
                            ]
                            
                            if cell_value in example_values:
                                is_example_row = True
                                break
                    
                    # è·³è¿‡ç¤ºä¾‹è¡Œ
                    if is_example_row:
                        df = df.iloc[1:]
                        logger.info(f"è·³è¿‡æ£€æµ‹åˆ°çš„ç¤ºä¾‹è¡Œï¼Œå‰©ä½™æ•°æ®è¡Œæ•°: {len(df)}")
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            data_rows = []
            original_columns = df.columns.tolist()
            if "æ‰§è¡Œç»“æœ" in original_columns:
                original_columns.remove("æ‰§è¡Œç»“æœ")
            
            for index, row in df.iterrows():
                row_data = {}
                for i, clean_col in enumerate(columns):
                    original_col = original_columns[i]
                    value = row[original_col]
                    # å¤„ç†NaNå€¼
                    if pd.isna(value):
                        row_data[clean_col] = None
                    else:
                        # ç¡®ä¿æ‰€æœ‰å€¼éƒ½è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹
                        if hasattr(value, 'item'):  # numpyç±»å‹
                            value = value.item()
                        row_data[clean_col] = str(value).strip()
                
                # è·³è¿‡ç©ºè¡Œ
                if any(v for v in row_data.values() if v):
                    data_rows.append(row_data)
            
            logger.info(f"Excelæ–‡ä»¶è§£æå®Œæˆ: å…±{len(data_rows)}è¡Œæ•°æ®")
            return data_rows, columns
            
        except Exception as e:
            logger.error(f"è§£æExcelæ–‡ä»¶å¤±è´¥: {str(e)}")
            raise FileProcessingException(f"è§£æExcelæ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def _validate_file(self, file_path: str):
        """éªŒè¯æ–‡ä»¶"""
        if not os.path.exists(file_path):
            raise FileProcessingException("æ–‡ä»¶ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(file_path)
        if file_size > self.max_file_size:
            raise FileProcessingException(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶({self.max_file_size / 1024 / 1024:.1f}MB)")
        
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        file_ext = Path(file_path).suffix.lower()
        if file_ext not in self.supported_extensions:
            raise FileProcessingException(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
    
    def validate_data_structure(self, data_rows: List[Dict[str, Any]], parameters: WorkflowParameters) -> List[str]:
        """
        éªŒè¯æ•°æ®ç»“æ„
        
        Args:
            data_rows: æ•°æ®è¡Œåˆ—è¡¨
            parameters: å·¥ä½œæµå‚æ•°
            
        Returns:
            éªŒè¯é”™è¯¯åˆ—è¡¨
        """
        errors = []
        
        try:
            # è·å–å¿…å¡«å‚æ•°
            required_params = [p.name for p in parameters.parameters if p.required]
            
            # éªŒè¯æ¯è¡Œæ•°æ®
            for row_idx, row_data in enumerate(data_rows, 1):
                # æ£€æŸ¥å¿…å¡«å‚æ•°
                for param_name in required_params:
                    if param_name not in row_data or not row_data[param_name]:
                        errors.append(f"ç¬¬{row_idx}è¡Œ: å¿…å¡«å‚æ•°'{param_name}'ä¸ºç©º")
                
                # éªŒè¯å‚æ•°ç±»å‹å’Œæ ¼å¼
                for param in parameters.parameters:
                    if param.name in row_data and row_data[param.name]:
                        value = row_data[param.name]
                        error = self._validate_parameter_value(param, value, row_idx)
                        if error:
                            errors.append(error)
            
            logger.info(f"æ•°æ®ç»“æ„éªŒè¯å®Œæˆ: {len(errors)}ä¸ªé”™è¯¯")
            return errors
            
        except Exception as e:
            logger.error(f"æ•°æ®ç»“æ„éªŒè¯å¤±è´¥: {str(e)}")
            return [f"æ•°æ®éªŒè¯å¤±è´¥: {str(e)}"]
    
    def _validate_parameter_value(self, param: WorkflowParameter, value: str, row_idx: int) -> Optional[str]:
        """éªŒè¯å‚æ•°å€¼"""
        try:
            if param.type == WorkflowParameterType.NUMBER:
                try:
                    float(value)
                except ValueError:
                    return f"ç¬¬{row_idx}è¡Œ: å‚æ•°'{param.name}'å¿…é¡»ä¸ºæ•°å­—"
            
            elif param.type == WorkflowParameterType.BOOLEAN:
                if value.lower() not in ['true', 'false', '1', '0', 'yes', 'no']:
                    return f"ç¬¬{row_idx}è¡Œ: å‚æ•°'{param.name}'å¿…é¡»ä¸ºå¸ƒå°”å€¼(true/false)"
            
            elif param.type == WorkflowParameterType.SELECT:
                if param.options and value not in param.options:
                    return f"ç¬¬{row_idx}è¡Œ: å‚æ•°'{param.name}'å€¼'{value}'ä¸åœ¨å¯é€‰é¡¹ä¸­: {param.options}"
            
            elif param.type == WorkflowParameterType.JSON:
                try:
                    import json
                    json.loads(value)
                except json.JSONDecodeError:
                    return f"ç¬¬{row_idx}è¡Œ: å‚æ•°'{param.name}'ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼"
            
            # æ£€æŸ¥é•¿åº¦é™åˆ¶
            if param.max_length and len(value) > param.max_length:
                return f"ç¬¬{row_idx}è¡Œ: å‚æ•°'{param.name}'é•¿åº¦è¶…è¿‡é™åˆ¶({param.max_length})"
            
            return None
            
        except Exception as e:
            return f"ç¬¬{row_idx}è¡Œ: å‚æ•°'{param.name}'éªŒè¯å¤±è´¥: {str(e)}"
    
    def generate_result_file(
        self, 
        original_file_path: str, 
        results: List[Dict[str, Any]], 
        output_path: str
    ) -> str:
        """
        ç”Ÿæˆç»“æœæ–‡ä»¶
        
        Args:
            original_file_path: åŸå§‹æ–‡ä»¶è·¯å¾„
            results: æ‰§è¡Œç»“æœåˆ—è¡¨ï¼ˆæŒ‰row_indexé¡ºåºæ’åˆ—ï¼‰
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            ç”Ÿæˆçš„ç»“æœæ–‡ä»¶è·¯å¾„
        """
        try:
            logger.info(f"å¼€å§‹ç”Ÿæˆç»“æœæ–‡ä»¶: {output_path}")
            
            # è¯»å–åŸå§‹æ–‡ä»¶
            df = pd.read_excel(original_file_path, sheet_name="æ‰¹é‡æ•°æ®", header=0)
            original_df = df.copy()  # ä¿ç•™åŸå§‹æ•°æ®æ¡†ç”¨äºè°ƒè¯•
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ä¸è§£ææ—¶å®Œå…¨ç›¸åŒçš„è¡Œè·³è¿‡é€»è¾‘
            # è¿™é‡Œå¿…é¡»ä¸ parse_excel_file æ–¹æ³•ä¸­çš„é€»è¾‘ä¿æŒä¸€è‡´
            
            # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦ä¸ºæè¿°è¡Œï¼ˆä¸è§£æé€»è¾‘ä¿æŒä¸€è‡´ï¼‰
            if len(df) > 0:
                first_row = df.iloc[0]
                is_description_row = False
                
                for col_idx, col_name in enumerate(df.columns):
                    if col_idx < len(first_row):
                        cell_value = str(first_row.iloc[col_idx]).strip()
                        clean_col_name = col_name.strip()
                        if clean_col_name.endswith(' *'):
                            clean_col_name = clean_col_name[:-2].strip()
                        
                        # å¦‚æœå•å…ƒæ ¼å€¼å°±æ˜¯åˆ—åæœ¬èº«ï¼Œæˆ–è€…æ˜¯å¸¸è§çš„æè¿°è¯ï¼Œåˆ™è®¤ä¸ºæ˜¯æè¿°è¡Œ
                        if (cell_value == clean_col_name or 
                            cell_value in ['æœç´¢è¯', 'å‚æ•°', 'è¾“å…¥', 'æ•°æ®', 'å†…å®¹', 'å€¼', 'ç¤ºä¾‹']):
                            is_description_row = True
                            break
                
                # è·³è¿‡æè¿°è¡Œï¼ˆä¸è§£æé€»è¾‘ä¸€è‡´ï¼‰
                if is_description_row:
                    df = df.iloc[1:]
                
                # ğŸ”§ ä¿®å¤ï¼šåº”ç”¨ä¸è§£ææ—¶ç›¸åŒçš„ç¤ºä¾‹è¡Œæ£€æµ‹é€»è¾‘
                if len(df) > 0:
                    # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦ä¸ºç¤ºä¾‹è¡Œ
                    first_row = df.iloc[0]
                    is_example_row = False
                    
                    for col_idx, col_name in enumerate(df.columns):
                        if col_idx < len(first_row):
                            cell_value = str(first_row.iloc[col_idx]).strip()
                            clean_col_name = col_name.strip()
                            if clean_col_name.endswith(' *'):
                                clean_col_name = clean_col_name[:-2].strip()
                            
                            # æ£€æµ‹å¸¸è§çš„ç¤ºä¾‹æ•°æ®ï¼ˆä¸è§£æé€»è¾‘å®Œå…¨ä¸€è‡´ï¼‰
                            example_values = [
                                'iPhone', 'iphone', 'IPHONE',  # å¸¸è§ç¤ºä¾‹æ‰‹æœº
                                'ç¤ºä¾‹', 'ä¾‹å­', 'example', 'sample',  # ç¤ºä¾‹æ ‡è¯†è¯
                                'ç¤ºä¾‹å‚æ•°', 'ç¤ºä¾‹æ•°æ®', 'ç¤ºä¾‹å†…å®¹',  # ç¤ºä¾‹å‚æ•°
                                'test', 'Test', 'TEST',  # æµ‹è¯•æ•°æ®
                                'æµ‹è¯•', 'æµ‹è¯•æ•°æ®', 'æµ‹è¯•å†…å®¹'  # ä¸­æ–‡æµ‹è¯•æ•°æ®
                            ]
                            
                            if cell_value in example_values:
                                is_example_row = True
                                break
                    
                    # è·³è¿‡ç¤ºä¾‹è¡Œ
                    if is_example_row:
                        df = df.iloc[1:]
                        logger.info(f"ç»“æœç”Ÿæˆæ—¶è·³è¿‡æ£€æµ‹åˆ°çš„ç¤ºä¾‹è¡Œï¼Œå‰©ä½™æ•°æ®è¡Œæ•°: {len(df)}")
            
            # è¿‡æ»¤ç©ºè¡Œï¼ˆä¸è§£æé€»è¾‘ä¸€è‡´ï¼‰
            df = df.dropna(how='all')
            
            # ğŸ”§ é‡è¦ï¼šç°åœ¨dfä¸­çš„è¡Œç´¢å¼•ä¸æ‰§è¡Œæ—¶çš„row_indexåº”è¯¥æ˜¯å¯¹åº”çš„
            logger.info(f"ğŸ“Š Excelæ–‡ä»¶å¤„ç†ç»“æœï¼š")
            logger.info(f"   åŸå§‹è¡Œæ•°: {len(original_df)}")
            logger.info(f"   å¤„ç†åè¡Œæ•°: {len(df)}")
            logger.info(f"   ç»“æœæ•°æ®è¡Œæ•°: {len(results)}")
            
            # éªŒè¯æ•°æ®è¡Œæ•°æ˜¯å¦åŒ¹é…
            if len(results) != len(df):
                logger.warning(f"âš ï¸ æ•°æ®è¡Œæ•°ä¸åŒ¹é…ï¼ç»“æœæ•°æ®{len(results)}è¡Œï¼ŒExcelæ•°æ®{len(df)}è¡Œ")
                # ä½†ä¸è¦æŠ›å‡ºå¼‚å¸¸ï¼Œç»§ç»­å¤„ç†
            
            # æ·»åŠ ç»“æœåˆ—
            if "æ‰§è¡Œç»“æœ" not in df.columns:
                df["æ‰§è¡Œç»“æœ"] = ""
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šç›´æ¥æŒ‰ç´¢å¼•å¡«å……ç»“æœï¼Œä¸å†ä½¿ç”¨ä»»ä½•åç§»
            # resultsåˆ—è¡¨å·²ç»æŒ‰row_indexæ’åºï¼Œç›´æ¥å¯¹åº”å¡«å……å³å¯
            for idx, result in enumerate(results):
                if idx < len(df):
                    logger.debug(f"å¡«å……ç»“æœ: è¡Œç´¢å¼•{idx}, ç»“æœ: {result}")
                    if result.get("success"):
                        df.iloc[idx, df.columns.get_loc("æ‰§è¡Œç»“æœ")] = result.get("output", "æ‰§è¡ŒæˆåŠŸ")
                    else:
                        df.iloc[idx, df.columns.get_loc("æ‰§è¡Œç»“æœ")] = f"æ‰§è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                else:
                    logger.warning(f"âš ï¸ ç»“æœç´¢å¼•{idx}è¶…å‡ºExcelæ•°æ®èŒƒå›´({len(df)})")
            
            # ğŸ”§ é‡è¦ï¼šä¿å­˜æ—¶éœ€è¦æ¢å¤å®Œæ•´çš„Excelç»“æ„
            # æˆ‘ä»¬éœ€è¦å°†ç»“æœåˆå¹¶å›åŸå§‹çš„Excelç»“æ„ä¸­
            
            # åˆ›å»ºæœ€ç»ˆçš„è¾“å‡ºæ•°æ®æ¡†
            final_df = original_df.copy()
            
            # æ·»åŠ ç»“æœåˆ—åˆ°åŸå§‹æ•°æ®æ¡†
            if "æ‰§è¡Œç»“æœ" not in final_df.columns:
                final_df["æ‰§è¡Œç»“æœ"] = ""
            
            # è®¡ç®—åŸå§‹æ•°æ®æ¡†ä¸­å®é™…æ•°æ®è¡Œçš„èµ·å§‹ä½ç½®
            data_start_row = len(original_df) - len(df)
            logger.info(f"ğŸ“ æ•°æ®èµ·å§‹è¡Œä½ç½®: {data_start_row}")
            
            # å°†ç»“æœå¡«å……åˆ°æ­£ç¡®çš„ä½ç½®
            for idx, result in enumerate(results):
                target_row = data_start_row + idx
                if target_row < len(final_df):
                    if result.get("success"):
                        final_df.iloc[target_row, final_df.columns.get_loc("æ‰§è¡Œç»“æœ")] = result.get("output", "æ‰§è¡ŒæˆåŠŸ")
                    else:
                        final_df.iloc[target_row, final_df.columns.get_loc("æ‰§è¡Œç»“æœ")] = f"æ‰§è¡Œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            
            # ä¿å­˜ç»“æœæ–‡ä»¶
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                final_df.to_excel(writer, sheet_name="æ‰§è¡Œç»“æœ", index=False)
                
                # è®¾ç½®æ ·å¼
                workbook = writer.book
                worksheet = writer.sheets["æ‰§è¡Œç»“æœ"]
                
                # è®¾ç½®è¡¨å¤´æ ·å¼
                header_font = Font(bold=True)
                for cell in worksheet[1]:
                    cell.font = header_font
                
                # è°ƒæ•´åˆ—å®½
                for column in worksheet.columns:
                    max_length = 0
                    column_letter = column[0].column_letter
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass
                    adjusted_width = min(max_length + 2, 50)
                    worksheet.column_dimensions[column_letter].width = adjusted_width
            
            logger.info(f"âœ… ç»“æœæ–‡ä»¶ç”Ÿæˆå®Œæˆ: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆç»“æœæ–‡ä»¶å¤±è´¥: {str(e)}")
            raise FileProcessingException(f"ç”Ÿæˆç»“æœæ–‡ä»¶å¤±è´¥: {str(e)}") 